{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting metpy\n",
      "  Using cached MetPy-0.12.2-py3-none-any.whl (319 kB)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.8/site-packages (from metpy) (3.2.2)\n",
      "Collecting pint>=0.10.1\n",
      "  Using cached Pint-0.16.1-py2.py3-none-any.whl (205 kB)\n",
      "Collecting xarray>=0.13.0\n",
      "  Using cached xarray-0.16.1-py3-none-any.whl (720 kB)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.8/site-packages (from metpy) (1.4.1)\n",
      "Requirement already satisfied: traitlets>=4.3.0 in /opt/conda/lib/python3.8/site-packages (from metpy) (4.3.3)\n",
      "Collecting pooch>=0.1\n",
      "  Using cached pooch-1.2.0-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.8/site-packages (from metpy) (1.18.5)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /opt/conda/lib/python3.8/site-packages (from metpy) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.1.0->metpy) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.1.0->metpy) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.1.0->metpy) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib>=2.1.0->metpy) (0.10.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from pint>=0.10.1->metpy) (20.4)\n",
      "Requirement already satisfied: setuptools>=38.4 in /opt/conda/lib/python3.8/site-packages (from xarray>=0.13.0->metpy) (49.2.0.post20200712)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from traitlets>=4.3.0->metpy) (4.4.2)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from traitlets>=4.3.0->metpy) (0.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from traitlets>=4.3.0->metpy) (1.15.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from pooch>=0.1->metpy) (2.24.0)\n",
      "Collecting appdirs\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas>=0.22.0->metpy) (2020.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=0.1->metpy) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=0.1->metpy) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=0.1->metpy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=0.1->metpy) (1.25.9)\n",
      "Installing collected packages: pint, xarray, appdirs, pooch, metpy\n",
      "Successfully installed appdirs-1.4.4 metpy-0.12.2 pint-0.16.1 pooch-1.2.0 xarray-0.16.1\n",
      "Collecting netCDF4\n",
      "  Using cached netCDF4-1.5.4-cp38-cp38-manylinux1_x86_64.whl (4.3 MB)\n",
      "Requirement already satisfied: numpy>=1.9 in /opt/conda/lib/python3.8/site-packages (from netCDF4) (1.18.5)\n",
      "Collecting cftime\n",
      "  Using cached cftime-1.2.1-cp38-cp38-manylinux1_x86_64.whl (271 kB)\n",
      "Installing collected packages: cftime, netCDF4\n",
      "Successfully installed cftime-1.2.1 netCDF4-1.5.4\n",
      "Collecting siphon\n",
      "  Using cached siphon-0.8.0-py2.py3-none-any.whl (66 kB)\n",
      "Requirement already satisfied: requests>=1.2 in /opt/conda/lib/python3.8/site-packages (from siphon) (2.24.0)\n",
      "Requirement already satisfied: numpy>=1.8 in /opt/conda/lib/python3.8/site-packages (from siphon) (1.18.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from siphon) (1.1.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.6 in /opt/conda/lib/python3.8/site-packages (from siphon) (4.9.1)\n",
      "Requirement already satisfied: protobuf>=3.0.0a3 in /opt/conda/lib/python3.8/site-packages (from siphon) (3.11.4)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests>=1.2->siphon) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=1.2->siphon) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=1.2->siphon) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=1.2->siphon) (2.10)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->siphon) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas->siphon) (2020.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4>=4.6->siphon) (2.0.1)\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.8/site-packages (from protobuf>=3.0.0a3->siphon) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from protobuf>=3.0.0a3->siphon) (49.2.0.post20200712)\n",
      "Installing collected packages: siphon\n",
      "Successfully installed siphon-0.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install metpy\n",
    "!pip install netCDF4\n",
    "!pip install siphon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import cartopy.crs as ccrs\n",
    "# import cartopy.feature as cfeature\n",
    "# import metpy.calc as mpcalc\n",
    "\n",
    "# from metpy.plots import StationPlot\n",
    "# from metpy.units import units\n",
    "# from scipy.ndimage import gaussian_filter\n",
    "# from siphon.catalog import TDSCatalog\n",
    "\n",
    "# from netCDF4 import Dataset, num2date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsoil.201707.nc: downloading...subsetting...saving...done.\n",
      "soill.201707.nc: downloading...subsetting...saving...done.\n",
      "soilw.201707.nc: downloading...subsetting...saving...done.\n",
      "tsoil.201708.nc: downloading...subsetting...saving...done.\n",
      "soill.201708.nc: downloading...subsetting...saving...done.\n",
      "soilw.201708.nc: downloading...subsetting...saving...done.\n",
      "tsoil.201709.nc: downloading...subsetting...saving...done.\n",
      "soill.201709.nc: downloading...subsetting...saving...done.\n",
      "soilw.201709.nc: downloading...subsetting...saving...done.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import Dataset, num2date\n",
    "from calendar import monthrange\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "from netCDF4 import date2num, num2date\n",
    "import numpy as np\n",
    "from pyproj import Proj\n",
    "from siphon.catalog import TDSCatalog\n",
    "import xarray as xr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# base_catalog = 'http://www.esrl.noaa.gov/psd/thredds/catalog/Datasets/NARR/pressure/catalog.xml'\n",
    "base_catalog = 'http://www.esrl.noaa.gov/psd/thredds/catalog/Datasets/NARR/subsurface/catalog.xml'\n",
    "# base_catalog = 'http://www.esrl.noaa.gov/psd/thredds/catalog/Datasets/NARR/monolevel/catalog.xml'\n",
    "main_cat = TDSCatalog(base_catalog)\n",
    "\n",
    "# Spatial location to find stuff\n",
    "points = [(69 , -135), (70, -134)]\n",
    "lats, lons = map(np.array, zip(*points))\n",
    "\n",
    "\n",
    "Subsurface_fields = ['tsoil','soill','soilw']\n",
    "\n",
    "for year, month, varname in itertools.product(([2017]), range(6, 10),Subsurface_fields):\n",
    "    \n",
    "    dsname = '{}.{:4d}{:02d}.nc'.format(varname, year, month)\n",
    "\n",
    "    if os.path.isfile('Data/Subsurface/'+dsname)==False: \n",
    "    \n",
    "        print('{}: downloading...'.format(dsname), end='')\n",
    "\n",
    "        # Grab it using opendap--manually convert to CF to work around the\n",
    "        # fact that missing_value and _FillValue differ\n",
    "        ds = xr.open_dataset(main_cat.datasets[dsname].access_urls['OPENDAP'],\n",
    "                             decode_cf=False)\n",
    "        ds = xr.conventions.decode_cf(ds, mask_and_scale=False)\n",
    "\n",
    "        # Grab the projection variable and convert our points to that\n",
    "        # Probably not strictly necessary\n",
    "        var = varname.split('.')[0]\n",
    "        proj_var = ds[ds[var].grid_mapping]\n",
    "        proj = Proj(proj='lcc', lat_0=proj_var.latitude_of_projection_origin,\n",
    "                lon_0=proj_var.longitude_of_central_meridian,\n",
    "                lat_1=proj_var.standard_parallel[0],\n",
    "                lat_2=proj_var.standard_parallel[1],\n",
    "                x_0=proj_var.false_easting, y_0=proj_var.false_northing,\n",
    "                ellps='sphere')\n",
    "        x, y = proj(lons, lats)\n",
    "        # Subset the data\n",
    "        print('subsetting...', end='')\n",
    "    #     ds.\n",
    "        pt_ds = ds.sel(x=x, y=y, method='nearest')\n",
    "        print('saving...', end='')\n",
    "\n",
    "        # Save to disk\n",
    "        pt_ds.to_netcdf('Data/Subsurface/'+dsname)\n",
    "        print('done.')\n",
    "\n",
    "    \n",
    "    \n",
    "base_catalog = 'http://www.esrl.noaa.gov/psd/thredds/catalog/Datasets/NARR/monolevel/catalog.xml'\n",
    "main_cat = TDSCatalog(base_catalog)\n",
    "Surface_fields = ['dswrf','dlwrf','uswrf.ntat','ulwrf.ntat']\n",
    "\n",
    "for year, varname in itertools.product(([2017]),Surface_fields):\n",
    "#     # Figure out what to grab\n",
    "\n",
    "    if os.path.isfile('Data/Subsurface/'+dsname)==False: \n",
    "        dsname = '{}.{:4d}.nc'.format(varname, year)\n",
    "        print('{}: downloading...'.format(dsname), end='')\n",
    "\n",
    "        # Grab it using opendap--manually convert to CF to work around the\n",
    "        # fact that missing_value and _FillValue differ\n",
    "        ds = xr.open_dataset(main_cat.datasets[dsname].access_urls['OPENDAP'],\n",
    "                             decode_cf=False)\n",
    "        ds = xr.conventions.decode_cf(ds, mask_and_scale=False)\n",
    "\n",
    "        # Grab the projection variable and convert our points to that\n",
    "        # Probably not strictly necessary\n",
    "        var = varname.split('.')[0]\n",
    "        proj_var = ds[ds[var].grid_mapping]\n",
    "        proj = Proj(proj='lcc', lat_0=proj_var.latitude_of_projection_origin,\n",
    "                lon_0=proj_var.longitude_of_central_meridian,\n",
    "                lat_1=proj_var.standard_parallel[0],\n",
    "                lat_2=proj_var.standard_parallel[1],\n",
    "                x_0=proj_var.false_easting, y_0=proj_var.false_northing,\n",
    "                ellps='sphere')\n",
    "        x, y = proj(lons, lats)\n",
    "        # Subset the data\n",
    "        print('subsetting...', end='')\n",
    "    #     ds.\n",
    "        pt_ds = ds.sel(x=x, y=y, method='nearest')\n",
    "        print('saving...', end='')\n",
    "\n",
    "        # Save to disk\n",
    "        pt_ds.to_netcdf('Data/Surface/'+dsname)\n",
    "        print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soill.201709.nc\n",
      "soill.201708.nc\n",
      "soilw.201707.nc\n",
      "soilw.201706.nc\n",
      "tsoil.201707.nc\n",
      "tsoil.201706.nc\n",
      "soill.201707.nc\n",
      "soill.201706.nc\n",
      "tsoil.201709.nc\n",
      "tsoil.201708.nc\n",
      "soilw.201709.nc\n",
      "soilw.201708.nc\n",
      "dlwrf.2017.nc\n",
      "ulwrf.ntat.2017.nc\n",
      "dswrf.2017.nc\n",
      "uswrf.ntat.2017.nc\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'air'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2888\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2889\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'air'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-0c5565c06d2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Data['soill'].plot()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'air'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;31m# Data['soill']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'air'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Dir='Data/Subsurface/'\n",
    "for i,dsname in enumerate(os.listdir(Dir)):\n",
    "    if \"2017\" not in dsname:\n",
    "        print('No')\n",
    "    else:\n",
    "        print(dsname)\n",
    "        fh = Dataset(Dir+dsname, mode='r')\n",
    "        time=fh.variables['time'][:]\n",
    "        lons = fh.variables['lon'][:]\n",
    "        lats = fh.variables['lat'][:]\n",
    "        var = dsname.split('.')[0]\n",
    "        query = fh.variables[var][:]\n",
    "#         print(query[:,0,:,:].mean(axis=(1,2)).mean()-273.15)\n",
    "#         print(query[:,-1,:,:].mean(axis=(1,2)).mean()-273.15)\n",
    "        fh.close()\n",
    "        if i == 0:\n",
    "            Data = pd.DataFrame(data={var:query[:,0,:,:].mean(axis=(1,2))},\n",
    "                            index=datetime(1800,1,1)+timedelta(hours=1)*time)\n",
    "        else:\n",
    "            Data = Data.append(pd.DataFrame(data={var:query[:,0,:,:].mean(axis=(1,2))},\n",
    "                            index=datetime(1800,1,1)+timedelta(hours=1)*time))\n",
    "            \n",
    "Dir='Data/Surface/'\n",
    "for i,dsname in enumerate(os.listdir(Dir)):\n",
    "    if \"2017\" not in dsname:\n",
    "        print('No')\n",
    "    else:\n",
    "        print(dsname)\n",
    "        fh = Dataset(Dir+dsname, mode='r')\n",
    "        time=fh.variables['time'][:]\n",
    "        lons = fh.variables['lon'][:]\n",
    "        lats = fh.variables['lat'][:]\n",
    "        var = dsname.split('.')[0]\n",
    "        query = fh.variables[var][:]\n",
    "#         print(query[:,0,:,:].mean(axis=(1,2)).mean()-273.15)\n",
    "#         print(query[:,-1,:,:].mean(axis=(1,2)).mean()-273.15)\n",
    "        fh.close()\n",
    "        if i == -1:\n",
    "            Data = pd.DataFrame(data={var:query[:,:,:].mean(axis=(1,2))},\n",
    "                            index=datetime(1800,1,1)+timedelta(hours=1)*time)\n",
    "        else:\n",
    "            Data = Data.append(pd.DataFrame(data={var:query[:,:,:].mean(axis=(1,2))},\n",
    "                            index=datetime(1800,1,1)+timedelta(hours=1)*time))\n",
    "# print(Data)\n",
    "Data.to_csv('CompiledData.csv')\n",
    "Data=Data.groupby(Data.index).mean()\n",
    "# Data['soill'].plot()\n",
    "plt.figure()\n",
    "plt.plot(Data.index,Data['air'])\n",
    "# Data['soill']\n",
    "print(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dswrf    731.8125\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# print(datetime(1800,1,1)+timedelta(hours=1)*time)\n",
    "# Temp = ma.filled(query).mean(axis=(1,2))\n",
    "# print(type(query[~query.mask]))\n",
    "# print(ma.getmask(query))\n",
    "print(Data.max())\n",
    "# print(time)\n",
    "# print(datetime(1800,1,1)+timedelta(hours=time.max()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.basemap import Basemap\n",
    "# # Get some parameters for the Stereographic Projection\n",
    "# lon_0 = lons.mean()\n",
    "# lat_0 = lats.mean()\n",
    "\n",
    "# m = Basemap(width=5000000,height=3500000,\n",
    "#             resolution='l',projection='stere',\\\n",
    "#             lat_ts=40,lat_0=lat_0,lon_0=lon_0)\n",
    "\n",
    "# # Because our lon and lat variables are 1D,\n",
    "# # use meshgrid to create 2D arrays\n",
    "# # Not necessary if coordinates are already in 2D arrays.\n",
    "lon, lat = np.meshgrid(lons, lats)\n",
    "xi, yi = m(lon, lat)\n",
    "\n",
    "# # Plot Data\n",
    "plt.figure()\n",
    "cs = plt.pcolor(xi,yi,np.squeeze(tmax))\n",
    "\n",
    "# Add Grid Lines\n",
    "m.drawparallels(np.arange(-80., 81., 10.), labels=[1,0,0,0], fontsize=10)\n",
    "m.drawmeridians(np.arange(-180., 181., 10.), labels=[0,0,0,1], fontsize=10)\n",
    "\n",
    "# Add Coastlines, States, and Country Boundaries\n",
    "m.drawcoastlines()\n",
    "m.drawstates()\n",
    "m.drawcountries()\n",
    "\n",
    "# Add Colorbar\n",
    "cbar = m.colorbar(cs, location='bottom', pad=\"10%\")\n",
    "cbar.set_label(tmax_units)\n",
    "\n",
    "# Add Title\n",
    "plt.title('DJF Maximum Temperature')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Read NARR Data from THREDDS server\n",
    "base_url = 'https://www.ncei.noaa.gov/thredds/catalog/model-narr-a-files/'\n",
    "\n",
    "# Programmatically generate the URL to the day of data we want\n",
    "cat = TDSCatalog(f'{base_url}{dt:%Y%m}/{dt:%Y%m%d}/catalog.xml')\n",
    "\n",
    "print(f'{base_url}{dt:%Y%m}/{dt:%Y%m%d}/catalog.xml')\n",
    "\n",
    "# Have Siphon find the appropriate dataset\n",
    "ds = cat.datasets.filter_time_nearest(dt)\n",
    "print(cat.datasets)\n",
    "# Interface with the data through the NetCDF Subset Service (NCSS)\n",
    "ncss = ds.subset()\n",
    "\n",
    "# Create an NCSS query with our desired specifications\n",
    "query = ncss.query()\n",
    "query.lonlat_box(north=60, south=18, east=300, west=225)\n",
    "query.all_times()\n",
    "query.add_lonlat()\n",
    "query.accept('netcdf')\n",
    "query.variables('Geopotential_height_isobaric',\n",
    "                'Temperature_isobaric',\n",
    "                'u-component_of_wind_isobaric',\n",
    "                'v-component_of_wind_isobaric')\n",
    "\n",
    "# Use the query to obtain our NetCDF data\n",
    "data = ncss.get_data(query)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import xarray as xr\n",
    "from siphon.catalog import TDSCatalog\n",
    "cat_url = 'https://www.esrl.noaa.gov/psd/thredds/catalog/Datasets/NARR/Dailies/pressure/catalog.xml'\n",
    "cat = TDSCatalog(cat_url)\n",
    "dsets = [cds.remote_access(use_xarray=True).reset_coords(drop=True).chunk({'time': 1, 'level': 1})\n",
    "         for cds in cat.datasets[:1]] # eventually want to use the whole catalog here\n",
    "# ds = xr.auto_combine(dsets)\n",
    "dsets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data.dimensions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Extract data and assign units\n",
    "tmpk = gaussian_filter(data.variables['Temperature_isobaric'][0], sigma=1.0) * units.K\n",
    "hght = 0\n",
    "uwnd = 0\n",
    "vwnd = 0\n",
    "\n",
    "# Extract coordinate data for plotting\n",
    "lat = data.variables['lat'][:]\n",
    "lon = data.variables['lon'][:]\n",
    "lev = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# %load solutions/extract.py\n",
    "\n",
    "# Cell content replaced by load magic replacement.\n",
    "# Extract data and assign units\n",
    "tmpk = gaussian_filter(data.variables['Temperature_isobaric'][0],\n",
    "                       sigma=1.0) * units.K\n",
    "hght = gaussian_filter(data.variables['Geopotential_height_isobaric'][0],\n",
    "                       sigma=1.0) * units.meter\n",
    "uwnd = gaussian_filter(data.variables['u-component_of_wind_isobaric'][0], sigma=1.0) * units('m/s')\n",
    "vwnd = gaussian_filter(data.variables['v-component_of_wind_isobaric'][0], sigma=1.0) * units('m/s')\n",
    "\n",
    "# Extract coordinate data for plotting\n",
    "lat = data.variables['lat'][:]\n",
    "lon = data.variables['lon'][:]\n",
    "lev = data.variables['isobaric1'][:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "time = data.variables['time1']\n",
    "print(time.units)\n",
    "vtime = num2date(time[0], units=time.units)\n",
    "# print(vtime)\n",
    "print(lat.max())\n",
    "print(lat.min())\n",
    "print(lon.max())\n",
    "print(lon.min())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Calcualte dx and dy for calculations\n",
    "dx, dy = mpcalc.lat_lon_grid_deltas(lon, lat)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Specify 850 hPa data\n",
    "ilev850 = np.where(lev==850)[0][0]\n",
    "hght_850 = hght[ilev850]\n",
    "tmpk_850 = 0\n",
    "uwnd_850 = 0\n",
    "vwnd_850 = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Specify 500 hPa data\n",
    "ilev500 = 0\n",
    "hght_500 = 0\n",
    "uwnd_500 = 0\n",
    "vwnd_500 = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Specify 300 hPa data\n",
    "ilev300 = 0\n",
    "hght_300 = 0\n",
    "uwnd_300 = 0\n",
    "vwnd_300 = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# %load solutions/get_850_500_300.py\n",
    "\n",
    "# Cell content replaced by load magic replacement.\n",
    "# Specify 850 hPa data\n",
    "ilev850 = np.where(lev == 850)[0][0]\n",
    "hght_850 = hght[ilev850]\n",
    "tmpk_850 = tmpk[ilev850]\n",
    "uwnd_850 = uwnd[ilev850]\n",
    "vwnd_850 = vwnd[ilev850]\n",
    "\n",
    "# Specify 500 hPa data\n",
    "ilev500 = np.where(lev == 500)[0][0]\n",
    "hght_500 = hght[ilev500]\n",
    "uwnd_500 = uwnd[ilev500]\n",
    "vwnd_500 = vwnd[ilev500]\n",
    "\n",
    "# Specify 300 hPa data\n",
    "ilev300 = np.where(lev == 300)[0][0]\n",
    "hght_300 = hght[ilev300]\n",
    "uwnd_300 = uwnd[ilev300]\n",
    "vwnd_300 = vwnd[ilev300]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
